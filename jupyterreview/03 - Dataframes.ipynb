{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataframes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e014318658578144"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What is a Pandas DataFrame?\n",
    "\n",
    "A Pandas DataFrame is a two-dimensional labeled data structure with columns of potentially different types. It is similar to a spreadsheet or SQL table, or a dictionary of Series objects. You can think of a DataFrame as a group of Series in which each Series represents a column. They are generally the most commonly used pandas object.\n",
    "\n",
    "DataFrames are capable of holding any Python data type, and they are also great for dealing with many types of heterogeneous datasets in a way that is efficient and easy to understand. This means you could have a DataFrame made up of other DataFrames, series, arrays, constant values, or even Python functions!\n",
    "\n",
    "## Why does it exist?\n",
    "\n",
    "Before Pandas, Python was majorly used for data munging and preparation. It had limited support for data analysis and modeling. Pandas solved this problem. Pandas DataFrame exists to provide Python developers and data analysts with an efficient, intuitive, and flexible tool to work with structured data sets, like a table in a SQL database or an Excel spreadsheet.\n",
    "\n",
    "Pandas DataFrame was designed to handle real-world data which is messy, comes in different types, and needs an effective tool for cleaning, transforming, manipulating, merging, aggregating, and aligning the data.\n",
    "\n",
    "## What is it good for?\n",
    "\n",
    "Here are some of the things that makes Pandas DataFrame a widely used data structure:\n",
    "\n",
    "**Ease of use**: Pandas DataFrames are easy to create and modify. They allow data manipulation in an intuitive, dictionary-like manner which makes the code easy to write and understand.\n",
    "\n",
    "**Heterogeneous Data**: DataFrame can contain data of various types like integer, float, string, etc., all within a single DataFrame.\n",
    "\n",
    "**Size Mutability**: DataFrames are mutable in size. Rows and columns can be added or dropped from DataFrame.\n",
    "\n",
    "**Data Alignment**: If data in DataFrame is altered, the associated labels will also change accordingly. It ensures a high level of data integrity.\n",
    "\n",
    "**Memory Efficient**: DataFrame is memory efficient as it doesn't duplicate data.\n",
    "\n",
    "**Robust Functionality**: Pandas DataFrames are equipped with a broad set of functionalities like aggregation, filtering, plotting, and others for handling and manipulating data.\n",
    "\n",
    "**Handling Missing Data**: Pandas can easily handle missing data by representing it as NaN and provide isnull(), notnull() functions to detect such data.\n",
    "\n",
    "Overall, Pandas DataFrame is an effective tool for data manipulation, cleaning, and analysis, which is why it's a favored choice among data scientists and analysts when working with data in Python.\n",
    "\n",
    "## What is it not good for?\n",
    "\n",
    "While Pandas brings a lot to the table for data analysis and manipulation tasks, there are indeed some areas where it may not be the best choice:\n",
    "\n",
    "Performance: Although Pandas is a powerful library for data analysis, it may not always be the fastest compared to other data processing libraries or languages.\n",
    "\n",
    "Concurrency and Parallelism: Pandas does not support concurrent operations out-of-the-box. While there are workarounds, Pandas wasn't built with parallel processing in mind.\n",
    "\n",
    "Multi-Dimensionality: Pandas primarily excels in handling two-dimensional data. There are some ways to handle three-dimensional data with the Panel data structure, but it's not as integrated or easy to use as 2D-structured DataFrame.\n",
    "\n",
    "Big Data Processing: If you're working with a really large dataset that is typically used in Big Data operations, then Pandas may be unsuitable. For this, frameworks like Apache Spark, Dask or Hadoop would be more suitable.\n",
    "\n",
    "Machine Learning Use Cases: While Pandas is great for data preprocessing in machine learning workflows, it isn't designed to perform machine learning tasks. Libraries such as Scikit-learn, TensorFlow, PyTorch should be used for actual machine learning modelling."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b5fa3a4c20fe8d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparisons with other technologies\n",
    "\n",
    "While dataframes may be new to you, they are in fact very similar in capability and use to other things you may have used, such as database tables, and excel spreadsheet.\n",
    "\n",
    "A pandas DataFrame, SQL table, and Excel spreadsheet are all tabular data structures that share some key similarities:\n",
    "\n",
    "**Two Dimensionality**: They all display data in a two-dimensional grid, with rows representing individual records and columns representing attributes or variables.\n",
    "\n",
    "**Structure**: They organize data in a structured way. The structure is primarily defined by the columns, which have a pre-set data type, such as integers, floats, strings, etc.\n",
    "\n",
    "**Labeled Axes**: They support labeled axes (rows and columns). In pandas, you could potentially have different data types in each column, like SQL tables. Excel spreadsheets also have labels for rows (1, 2, 3, etc.) and columns (A, B, C, etc.).\n",
    "\n",
    "**Subsetting**: They all allow for subsetting, filtering, and manipulating data. This includes actions like selecting a single column or multiple columns, filtering rows based on a condition, etc.\n",
    "\n",
    "**Aggregation Functionality**: All three provide the ability to perform aggregations, such as calculating the sum, average, count, min, max, etc., on a specified column or set of columns.\n",
    "\n",
    "**Join Operations**: Like SQL tables, DataFrame also offers join operations (merge in pandas) to combine different datasets based on a common attribute. In Excel also, this can be done using VLOOKUP and other lookup/match functions.\n",
    "\n",
    "**Missing Data Handling**: They all allow handling missing data. In pandas, missing data is usually represented as NaN. In SQL, it is NULL, and in Excel, it could be an empty cell or a variety of error codes.\n",
    "\n",
    "In short, pandas DataFrames, SQL tables, and Excel spreadsheets all provide structured, grid-like interfaces to manipulating and analyzing data, making them fundamental tools in data science and analytics.  When writing pandas software, it is often instructive to think about how you would solve your program in SQL, if you know that language, or in excel. Often, some of the same ideas will work in both contexts."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "510f9e613b34eef1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pandas Performance\n",
    "\n",
    "When working with Pandas DataFrames, especially large ones, there are several performance considerations to keep in mind:\n",
    "\n",
    "**Memory Usage**: Pandas loads the entire DataFrame into memory, which can be a problem if you're working with a large dataset that you're trying to process on a machine with limited RAM. Consider using chunking, which allows you to load data in smaller chunks, or using data types which require less memory, if possible.\n",
    "\n",
    "**Vectorization**: Try to use vectorized operations provided by Pandas when possible, instead of applying operations row by row, or cell by cell, which can significantly slow down the computations.\n",
    "\n",
    "**Avoid Chained Indexing**: Chained indexing (e.g., df[condition][column_name]) can lead to unpredictable results. Instead, use .loc or .iloc for a more predictable performance.\n",
    "\n",
    "**Use Categorical Data Type**: If a column in your DataFrame contains a limited set of values - such as a city name or person's gender - then converting it to a categorical type can save memory and improve performance.\n",
    "\n",
    "**Use Appropriate Indexing**: Appropriate use of indexes, just like in SQL, can enhance the selection, merging, and joining of data frames. Multi-indexing and Hierarchical indexing can also help you work with higher-dimensional data.\n",
    "\n",
    "**Inplace Operations**: Certain operations in Pandas provide an inplace parameter which, when set to True, can help to save memory by modifying the existing DataFrame rather than creating a new one.  While true, it also leads to destructive state modification and can being about problems.  Only use in cases where it can be shown that the `inpalce` operation wont corrupt shared state.\n",
    "\n",
    "**Avoid Looping (when possible)**: Loops in Python can be slow and can be especially so when used with a Pandas DataFrame. Try to use built-in Pandas functions and vectorized operations when possible.  For small data sets, it really doesn't matter, but for large ones, it can be a problem.\n",
    "\n",
    "**Leverage Built-In Functions**: Pandas has a wealth of functionality built-in. Always explore whether there's a built-in function in Pandas that can do the task more optimally.\n",
    "\n",
    "**Parallel Processing**: For really large dataframes, consider using libraries such as Dask to leverage parallel processing.\n",
    "\n",
    "**Consider Scale**: For particularly large datasets or computationally heavy tasks, consider whether pandas is the right tool for the job. It might be that your task is better suited to a distributed compute tool or solution, such as Apache Spark, or even a data storage system like Dask.\n",
    "\n",
    "Remember, these are guidelines, and the exact optimizations depend on the nature of the data and the kind of analysis or transformations you're performing. The key is to always keep in mind the trade-off between memory and speed and manage your resources wisely."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "734d2cfe50db3cac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Storage\n",
    "\n",
    "In Pandas, a DataFrame is represented internally as a collection of Series, where each Series represents a column. Each Series object uses a one-dimensional ndarray (from NumPy) to store data. These Series objects share the same index, which forms the row index for the entire DataFrame.\n",
    "\n",
    "The data in these ndarray data structures can be of different types (integers, strings, floating-point numbers, Python objects, etc.) in compliance to the respective column. This allows for a flexible and efficient approach to manage memory and speed up computations.\n",
    "\n",
    "Indexes in Pandas are also stored as ndarray objects. This allows for fast lookups of data along either axis of the DataFrame.\n",
    "\n",
    "While the data is stored primarily in contiguous one-dimensional blocks for performance, flexibility, and memory use reasons, the DataFrame allows you to deal with the data in a higher-dimensional way.\n",
    "\n",
    "## Data Manipulation and Operations\n",
    "\n",
    "When performing operations on a DataFrame, Pandas typically operates on the underlying Series objects in a vectorized way. This allows for very fast data manipulation and transformation.\n",
    "\n",
    "For example, if you perform an arithmetic operation between two DataFrames, Pandas aligns rows and columns by their labels, applies the operation across all aligned elements in a vectorized way, and returns a new DataFrame.\n",
    "\n",
    "When selecting or assigning data, Pandas will return or modify views on the original data if possible. This can help to avoid unnecessary data copying. However, in cases where this isn't possible, it will copy the data.\n",
    "\n",
    "Furthermore, operations that aggregate data, like sum(), mean(), etc., are treated as reducing operations across the specified axis of the DataFrame.\n",
    "\n",
    "## Miscellaneous Features\n",
    "\n",
    "Pandas leverages many other features for flexibility, like allowing to have hierarchical row and column labels (MultiIndex). This offers a way to work with higher dimensional data in a lower dimensional form.\n",
    "\n",
    "Handling missing data is another key specialized feature in Pandas. It represents missing or NA values using the NaN floating-point value, which makes computations seamless.\n",
    "\n",
    "In summary, the implementation of a Pandas DataFrame is aimed at providing an efficient, flexible, and performant way to work with structured data in Python. This is achieved through careful memory management, vectorized operations for speed, flexibility in dealing with different data types, and treating axes meaningfully depending on the context."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f693e6be851a33af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In our work, we mostly follow the rules listed above for performance. Our data is rarely big enough to need it, but if the fast way is no more work, or possibly even less work, than the slow way, and there is no other cost, then there is no reason not to do it the fast way.\n",
    "\n",
    "You will find that we use a somewhat limited number of pandas built in functions, but that is not because there are anything wrong with the others, just that most of our work can be easily done with just a few.  \n",
    "\n",
    "Keeping up on what pandas can do is an important side job for us all to follow.  I haven't written a line of our code with out the pandas documentation being up where I can find it.  There is a lot these functions can do, lots of optional parameters, etc. I'm often poking around looking for some built in function that will do what I want it to.  Keep an eye out for ways to use built in functions rather than writing you're own.  They are generally faster, more correct, and more flexible than something you might write on your own.   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98c3c38495ede0f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T18:39:11.372127731Z",
     "start_time": "2023-12-20T18:39:11.371595365Z"
    }
   },
   "id": "135e6962db79c4d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
